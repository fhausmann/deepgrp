{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Training of the best model found be hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import os\n",
    "from os import path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import hyperopt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from deepgrp import training, preprocessing\n",
    "from deepgrp import model as deepgrp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = \"..\"\n",
    "GENOMEBUILD = \"hg19\"\n",
    "TRAIN_CHR = \"chr11\"\n",
    "VAL_CHR = \"chr20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = path.join(PROJECT_ROOT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a) Loading pickled hyperopt results if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESULTS_FILE:\n",
    "    with open(RESULTS_FILE, 'rb') as file:\n",
    "        best = pickle.load(file).best_trial\n",
    "    hyperparameter = deepgrp_model.Options(**best['result']['options'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b) Load from toml if hyperparameter are not loaded yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOML_FILE = path.join(PROJECT_ROOT_DIR, \"defaults.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hyperparameter is None:\n",
    "    with open(TOML_FILE, 'r') as file:\n",
    "        hyperparameter = deepgrp_model.Options.from_toml(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train DeepGRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    hyperparameter: deepgrp_model.Options, data: Tuple[preprocessing.Data,\n",
    "                                                       preprocessing.Data]\n",
    ") -> Tuple[str, float]:\n",
    "    \"\"\" Train model and time the training \"\"\"\n",
    "    starttime = time.time()\n",
    "    logdir = deepgrp_model.create_logdir(hyperparameter)\n",
    "    model = deepgrp_model.create_model(hyperparameter)\n",
    "    training.training(data, hyperparameter, model, logdir)\n",
    "    endtime = time.time()\n",
    "    return logdir, endtime - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfwd = np.load(path.join(datadir, GENOMEBUILD, TRAIN_CHR + \".fa.gz.npz\"))['fwd']\n",
    "Xfwd_val = np.load(path.join(datadir, GENOMEBUILD,\n",
    "                             VAL_CHR + \".fa.gz.npz\"))['fwd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = preprocessing.preprocess_y(path.join(datadir,\n",
    "                                         GENOMEBUILD + \".bed\"), TRAIN_CHR,\n",
    "                               Xfwd.shape[1], hyperparameter.repeats_to_search)\n",
    "Y_val = preprocessing.preprocess_y(path.join(datadir, GENOMEBUILD + \".bed\"),\n",
    "                                   VAL_CHR, Xfwd_val.shape[1],\n",
    "                                   hyperparameter.repeats_to_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove leading and trailing N's for training, because they do not contain repetitive elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfwd, Y = preprocessing.drop_start_end_n(Xfwd, Y)\n",
    "Xfwd_val, Y_val = preprocessing.drop_start_end_n(Xfwd_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "train_data = preprocessing.Data(Xfwd, Y)\n",
    "val_data = preprocessing.Data(Xfwd_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Run the training for DeepGRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_TO_TRAIN = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(MODELS_TO_TRAIN):\n",
    "    modelname, runtime = train_model(hyperparameter, (train_data, val_data))\n",
    "    results[modelname] = runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save model to HDF5 format for the python tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_to_model(hyperparameter: deepgrp_model.Options, logdir: str,\n",
    "                     output: str) -> None:\n",
    "    \"\"\"Saves model to HDF5 format\"\"\"\n",
    "    ckpt = tf.train.Checkpoint()\n",
    "    manager = tf.train.CheckpointManager(ckpt, logdir, max_to_keep=None)\n",
    "    if manager.latest_checkpoint is None:\n",
    "        raise FileNotFoundError(logdir)\n",
    "    model = deepgrp_model.create_model(hyperparameter)\n",
    "    model.load_weights(manager.latest_checkpoint).expect_partial()\n",
    "    model.save(output + '_' + path.basename(manager.latest_checkpoint) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for logdir in results:\n",
    "    weights_to_model(hyperparameter, logdir,\n",
    "                     logdir.replace('tf_logs/run-', './model_'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save training times to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.Series(results).to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['model'] = 'DeepGRP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.rename({'index': 'modelname', 0: 'training time'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('training_times.csv')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:hydrogen"
  },
  "kernelspec": {
   "display_name": "Python (deepgrp)",
   "language": "python",
   "name": "deepgrp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
