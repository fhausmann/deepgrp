{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization for DeepGRP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from deepgrp.model import Options\n",
    "from deepgrp.preprocessing import preprocess_y, drop_start_end_n, Data\n",
    "from deepgrp.optimization import run_a_trial, build_and_optimize\n",
    "from hyperopt import hp\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting basic configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CHR = 'chr11'\n",
    "VAL_CHR = 'chr20'\n",
    "GENOMEBUILD = \"hg19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = path.join(PROJECT_ROOT_DIR, \"data\")\n",
    "train_data_file = path.join(datadir, GENOMEBUILD, TRAIN_CHR + \".fa.gz.npz\")\n",
    "val_data_file = path.join(datadir, GENOMEBUILD, VAL_CHR + \".fa.gz.npz\")\n",
    "true_annotations = path.join(datadir, GENOMEBUILD + \".bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.repeats_to_search = [1, 2, 3, 4]\n",
    "options.attention = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfwd = np.load()['fwd']\n",
    "Xfwd_val = np.load()['fwd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = preprocess_y(true_annotations, TRAIN_CHR, Xfwd.shape[1],\n",
    "                 options.repeats_to_search)\n",
    "Y_val = preprocess_y(true_annotations, VAL_CHR, Xfwd_val.shape[1],\n",
    "                     options.repeats_to_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove leading and trailing N's for training, because they do not contain repetitive elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfwd, Y = drop_start_end_n(Xfwd, Y)\n",
    "Xfwd_val, Y_val = drop_start_end_n(Xfwd_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data(Xfwd, Y)\n",
    "val_data = Data(Xfwd_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Defining a hyperopt search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_SPACE = {\n",
    "    'vecsize': hp.qnormal('vecsize', 200, 20, 2),\n",
    "    'gru_units': hp.qnormal('gru_units', 34, 5, 2),\n",
    "    'gru_dropout': hp.uniform('gru_dropout', 0, 0.4),\n",
    "    'momentum': hp.uniform('momentum', 0, 1),\n",
    "    'learning_rate': hp.lognormal('learning_rate', -7, 0.5),\n",
    "    'rho': hp.uniform('decay', 0, 1),\n",
    "    'repeat_probability': hp.uniform('repeat_probability', 0, 0.49),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build an optimizable function\n",
    "\n",
    "The function has the varying hyperparameter (dict) as single argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = partial(build_and_optimize, train_data, val_data, 50, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run the optimization\n",
    "\n",
    "Per default the negative Matthews correlation coefficient gets minimized, meaning maximizing the Matthews correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 100\n",
    "save_step = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, runs, save_step):\n",
    "    try:\n",
    "        run_a_trial(SEARCH_SPACE, objective, PROJECT_ROOT_DIR, save_step)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:hydrogen"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
